{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC 311 Complaints 2017 Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as opj\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import HTTPError, ConnectionError\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sodapy import Socrata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_DATASET_URL = ('https://s3.amazonaws.com/SplitwiseBlogJB/'\n",
    "                          '2010+Census+Population+By+Zipcode+(ZCTA).csv')\n",
    "\n",
    "NYC_ZIPCODES_DATASET_URL = ('https://www.health.ny.gov/statistics/cancer/'\n",
    "                            'registry/appendix/neighborhoods.htm')\n",
    "\n",
    "COMPLAINTS_DATASET_URL = ('https://data.cityofnewyork.us/resource/fhrw-4uyv.csv?'\n",
    "                          '$where=date_extract_y(created_date)=2017&$limit={n_records}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, how many records were there in 2017?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_records(year=2017):\n",
    "    with Socrata('data.cityofnewyork.us', None) as client:\n",
    "        query = \"\"\"\n",
    "        select count(unique_key)\n",
    "        where date_extract_y(created_date) = 2017\n",
    "        \"\"\"\n",
    "        \n",
    "        n_records = int(client.get('fhrw-4uyv' , query=query)[0]['count_unique_key'])\n",
    "        \n",
    "    return n_records\n",
    "\n",
    "n_records = get_n_records()\n",
    "print(n_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = requests.get(COMPLAINTS_DATASET_URL.format(n_records=n_records), stream=True)\n",
    "\n",
    "with open('../data/raw/nyc-311-complaints-2017.csv', 'wb') as fout:\n",
    "    for chunk in response.iter_content(32 * 1024):\n",
    "        fout.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that we retrieved all the records we expected to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l ../data/raw/nyc-311-complaints-2017.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! Looks like we're good to go (the \"extra\" row being the header, of course), since that matches the expected number of complaints recorded in 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 ../data/raw/nyc-311-complaints-2017.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 311 Data Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_population_by_zip(url):\n",
    "    \"\"\" Retrieves 2010 Census population by ZIP code data \"\"\"\n",
    "    try:\n",
    "        population_by_zip = pd.read_csv(url)\n",
    "        return population_by_zip\n",
    "    except HTTPError as e:\n",
    "        print(e)\n",
    "        \n",
    "def scrape_nyc_zips(url):\n",
    "    \"\"\" Scrapes table of NYC zipcodes from New York State Department\n",
    "    of Health website \"\"\"\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        return r\n",
    "    except HTTPError as e:\n",
    "        print(\"NYC neighborhood ZIP code lookup table not found:\", e)\n",
    "\n",
    "\n",
    "# TODO: Refactor to have utility functions for, for example, the\n",
    "# \"tidying\" aspects and the conversion aspects ... and rename this\n",
    "# function to something more sensible\n",
    "def tidy_nyc_zips(html):\n",
    "    \"\"\" Wrangle HTML table of NYC ZIP codes into a \"tidy\" data frame\n",
    "\n",
    "    Args:\n",
    "        html (requests.models.Response):\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame:\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: This seems too ugly and hacky so find a more elegant\n",
    "    # solution\n",
    "    borough_zips = (\n",
    "        pd.read_html(html.content, header=0)[0]\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    borough_zips.loc[borough_zips['ZIP Codes'].isnull(), 'Borough'] = np.nan\n",
    "    borough_zips.loc[:, 'ZIP Codes'] = \\\n",
    "        borough_zips.loc[:, 'ZIP Codes'].str.replace(' ', '')\n",
    "\n",
    "    borough_zips.loc[:, 'ZIP Codes'] = (\n",
    "        borough_zips.loc[:, 'ZIP Codes']\n",
    "                    .combine_first(borough_zips['Neighborhood'])\n",
    "    )\n",
    "\n",
    "    # TODO: keep the neighborhood information, even though it's not\n",
    "    # currently necessary for this analysis\n",
    "    borough_zips.drop('Neighborhood', axis=1, inplace=True)\n",
    "    borough_zips.loc[:, 'Borough'] = \\\n",
    "        borough_zips.loc[:, 'Borough'].ffill()\n",
    "\n",
    "    # Overwrite the comma-separated string \"list\" in the cell\n",
    "    # with an actual list of integers\n",
    "    borough_zips.loc[:, 'ZIP Codes'] = (\n",
    "        borough_zips.loc[:, 'ZIP Codes']\n",
    "                    .apply(lambda x: x.split(','))\n",
    "    )\n",
    "\n",
    "    # TODO: Write utility function for this pattern\n",
    "    borough_zips = (\n",
    "        borough_zips.set_index(['index', 'Borough'])\n",
    "                    .loc[:, 'ZIP Codes']\n",
    "                    .apply(pd.Series) # Expand the list of \n",
    "                    .stack()\n",
    "                    .reset_index()\n",
    "    )\n",
    "\n",
    "    borough_zips.drop(['index', 'level_2'], axis=1, inplace=True)\n",
    "    borough_zips.columns = \\\n",
    "        'borough zip_code'.split(' ')\n",
    "    borough_zips.loc[:, 'zip_code'] = \\\n",
    "        borough_zips.loc[:, 'zip_code'].astype(int)\n",
    "\n",
    "    return borough_zips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "### NYC 311 Complaints 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_frame(complaints):\n",
    "    \n",
    "    complaints.loc[:, 'unique_key'] = \\\n",
    "    complaints.loc[:, 'unique_key'].astype(int)\n",
    "\n",
    "    complaints.loc[:, 'borough'] = (\n",
    "        complaints.loc[:, 'borough']\n",
    "                  .str.title()\n",
    "                  .astype('category')\n",
    "    )\n",
    "\n",
    "    complaints.loc[:, 'city'] = (\n",
    "        complaints.loc[:, 'city']\n",
    "                  .str.title()\n",
    "                  .astype('category')\n",
    "    )\n",
    "\n",
    "    complaints.loc[:, 'complaint_type'] = \\\n",
    "        complaints.loc[:, 'complaint_type'].astype('category')\n",
    "\n",
    "    complaints.loc[:, 'incident_zip'] = \\\n",
    "        complaints.loc[:, 'incident_zip'].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    complaints.loc[:, 'created_date'] = \\\n",
    "        complaints.loc[:, 'created_date'].apply(pd.to_datetime)\n",
    "    \n",
    "    complaints = complaints.replace('Unspecified', np.nan)\n",
    "\n",
    "    is_borough = complaints['city'].isin(['Bronx', 'Brooklyn', 'Manhattan',\n",
    "                                      'Queens', 'Staten Island'])\n",
    "    complaints.loc[~is_borough, 'city'] = np.nan\n",
    "\n",
    "    complaints.loc[:, 'borough'] = (\n",
    "        complaints.loc[:, 'borough']\n",
    "                  .combine_first(complaints['city'])\n",
    "    )\n",
    "\n",
    "    complaints.drop('city', axis=1, inplace=True)\n",
    "    \n",
    "    return complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "keep = ['unique_key', 'created_date', 'borough', 'city', 'incident_zip', \n",
    "        'latitude', 'longitude', 'complaint_type', 'descriptor']\n",
    "\n",
    "chunksize = 10 ** 5\n",
    "dfs = {}\n",
    "for idx, df in enumerate(pd.read_csv('nyc-311-complaints-2017.csv',\n",
    "                                     usecols=keep,\n",
    "                                     chunksize=chunksize,\n",
    "                                     low_memory=False)):\n",
    "    dfs[idx] = clean_frame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = pd.concat(dfs.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2010 Census Population by ZIP Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_by_zip = get_population_by_zip(POPULATION_DATASET_URL)\n",
    "population_by_zip.columns = 'zip_code population'.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NYC ZIP Codes\n",
    "\n",
    "There are some non-NYC ZIP codes in the dataset, so we'd like to safely filter those out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = scrape_nyc_zips(NYC_ZIPCODES_DATASET_URL)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = scrape_nyc_zips(NYC_ZIPCODES_DATASET_URL)\n",
    "nyc_zips = tidy_nyc_zips(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_zips.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_by_zip_nyc = nyc_zips.merge(\n",
    "    population_by_zip,\n",
    "    on='zip_code',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_by_zip_nyc.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_by_borough = (\n",
    "    population_by_zip_nyc.groupby('borough', as_index=False)\n",
    "                          .population\n",
    "                           .sum()\n",
    ")\n",
    "population_by_borough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Google, NYC had a population of 8.194 million in 2010. The scraped and merged dataset says that the 2010 population is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_by_borough['population'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It isn't exactly the same, but it's close enough for the present purposes to ignore futher investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_by_zip_nyc.to_csv('../data/cleaned/population-by-zip-nyc-2010.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = complaints.merge(\n",
    "    population_by_zip_nyc[['borough', 'zip_code', 'population']],\n",
    "    left_on='incident_zip',\n",
    "    right_on='zip_code',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "complaints.loc[:, 'borough'] = (\n",
    "    complaints.loc[:, 'borough_x']\n",
    "              .combine_first(complaints['borough_y'])\n",
    ")\n",
    "\n",
    "complaints.drop(['borough_x', 'borough_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = [\n",
    "    'unique_key', 'created_date', 'borough', 'zip_code', \n",
    "    'latitude', 'longitude', 'complaint_type', 'descriptor'\n",
    "]\n",
    "                \n",
    "complaints[column_order].to_csv(\n",
    "    '../data/cleaned/nyc-311-complaints.csv.gz',\n",
    "    compression='gzip',\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
